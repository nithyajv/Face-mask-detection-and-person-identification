{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting TensorFlow\n",
      "  Using cached tensorflow-2.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 56 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 2.0 MB/s eta 0:00:01   |                                | 40 kB 1.8 MB/s eta 0:00:09     |███████████████████████▌        | 10.6 MB 1.2 MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5 MB 645 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from TensorFlow) (45.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from TensorFlow) (1.14.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 145 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 52 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.46.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 876 kB/s eta 0:00:01     |█████████████▊                  | 1.9 MB 1.2 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[K     |████████████████████████████████| 438 kB 100 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 22 kB/s  eta 0:00:01     |█████████████████▋              | 3.2 MB 1.6 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 414 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting numpy>=1.20\n",
      "  Downloading numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.9 MB 1.6 MB/s eta 0:00:01    |▊                               | 378 kB 1.6 MB/s eta 0:00:11     |██████████▍                     | 5.5 MB 1.9 MB/s eta 0:00:07     |█████████████                   | 6.9 MB 1.6 MB/s eta 0:00:07     |███████████████████▋            | 10.3 MB 216 kB/s eta 0:00:31     |██████████████████████████▌     | 14.0 MB 1.1 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/lib/python3/dist-packages (from TensorFlow) (20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/nimmy/.local/lib/python3.8/site-packages (from TensorFlow) (3.10.0.2)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 474 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->TensorFlow) (3.1.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->TensorFlow) (0.34.2)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->TensorFlow) (2.22.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/nimmy/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->TensorFlow) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->TensorFlow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/nimmy/.local/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->TensorFlow) (0.4.8)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=c08e621444f1736e4f0e0a77a7a79b75df0c6675e7d9b4f7e15a41908fedb631\n",
      "  Stored in directory: /home/nimmy/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: numpy, keras-preprocessing, libclang, h5py, tensorflow-io-gcs-filesystem, google-pasta, keras, protobuf, grpcio, gast, tensorflow-estimator, flatbuffers, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, requests-oauthlib, rsa, cachetools, google-auth, google-auth-oauthlib, absl-py, tensorboard, opt-einsum, astunparse, wrapt, termcolor, TensorFlow\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.8 are installed in '/home/nimmy/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/home/nimmy/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/home/nimmy/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/nimmy/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/nimmy/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed TensorFlow-2.9.1 absl-py-1.0.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-1.12 gast-0.4.0 google-auth-2.6.6 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.46.3 h5py-3.7.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.1 numpy-1.22.4 opt-einsum-3.3.0 protobuf-3.19.4 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0 werkzeug-2.1.2 wrapt-1.14.1\n",
      "Requirement already satisfied: keras in /home/nimmy/.local/lib/python3.8/site-packages (2.9.0)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.5 MB 27 kB/s  eta 0:00:01     |█████████████▍                  | 25.3 MB 1.9 MB/s eta 0:00:19     |██████████████████████████████▋ | 57.9 MB 1.6 MB/s eta 0:00:02     |███████████████████████████████▏| 59.0 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /home/nimmy/.local/lib/python3.8/site-packages (from opencv-python) (1.22.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.64\n"
     ]
    }
   ],
   "source": [
    "!pip3 install TensorFlow\n",
    "!pip3 install keras\n",
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from face_recognition) (7.0.0)\n",
      "Collecting dlib>=19.7\n",
      "  Downloading dlib-19.24.0.tar.gz (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting face-recognition-models>=0.3.0\n",
      "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 100.1 MB 10 kB/s  eta 0:00:01   |█▍                              | 4.2 MB 1.6 MB/s eta 0:01:00     |█████████▌                      | 29.8 MB 1.6 MB/s eta 0:00:45     |█████████████▏                  | 41.4 MB 1.9 MB/s eta 0:00:32     |██████████████████▎             | 57.2 MB 1.8 MB/s eta 0:00:24     |████████████████████▌           | 64.3 MB 1.4 MB/s eta 0:00:27     |█████████████████████████████▏  | 91.3 MB 1.5 MB/s eta 0:00:06\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/nimmy/.local/lib/python3.8/site-packages (from face_recognition) (1.22.4)\n",
      "Requirement already satisfied: Click>=6.0 in /usr/lib/python3/dist-packages (from face_recognition) (7.0)\n",
      "Building wheels for collected packages: dlib, face-recognition-models\n",
      "  Building wheel for dlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dlib: filename=dlib-19.24.0-cp38-cp38-linux_x86_64.whl size=4186227 sha256=0e6740f625f9f8d10d66f4c3d4a2c90e107026d46b69d393b097f4af0dc5d917\n",
      "  Stored in directory: /home/nimmy/.cache/pip/wheels/4c/d8/2d/a83b10e7bf10cd7d8bef36bf4dcd15b0c9ebf98f990bc984dd\n",
      "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566172 sha256=e411daacb8a2112c3fd94b51a2990d2a958ff72b9e26a0f79358ac19f2c547c3\n",
      "  Stored in directory: /home/nimmy/.cache/pip/wheels/b4/4b/8f/751e99d45f089bdf366a7d3e5066db3c2b84a62e4377f534d7\n",
      "Successfully built dlib face-recognition-models\n",
      "Installing collected packages: dlib, face-recognition-models, face-recognition\n",
      "\u001b[33m  WARNING: The scripts face_detection and face_recognition are installed in '/home/nimmy/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed dlib-19.24.0 face-recognition-1.3.0 face-recognition-models-0.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/home/nimmy/Desktop/MALU/vscode/project/facemask.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nimmy/Desktop/MALU/vscode/project/facemask.ipynb#ch0000002?line=25'>26</a>\u001b[0m classifier \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mCascadeClassifier(haar_xml)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nimmy/Desktop/MALU/vscode/project/facemask.ipynb#ch0000002?line=26'>27</a>\u001b[0m ret, img \u001b[39m=\u001b[39m vid_source\u001b[39m.\u001b[39mread()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nimmy/Desktop/MALU/vscode/project/facemask.ipynb#ch0000002?line=27'>28</a>\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(img, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2GRAY)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nimmy/Desktop/MALU/vscode/project/facemask.ipynb#ch0000002?line=28'>29</a>\u001b[0m faces \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mdetectMultiScale(gray)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nimmy/Desktop/MALU/vscode/project/facemask.ipynb#ch0000002?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m(x,y,w,h) \u001b[39min\u001b[39;00m faces:\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import cv2\n",
    "#import face_recognition\n",
    "import numpy as np\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "import smtplib\n",
    "import pkg_resources\n",
    "haar_xml = pkg_resources.resource_filename('cv2', 'data/haarcascade_frontalface_default.xml')\n",
    "\n",
    "root = Tk()\n",
    "root.withdraw()\n",
    "\n",
    "model = load_model('face_mask_detection_alert_system.h5', compile=False)\n",
    "\n",
    "vid_source = cv2.VideoCapture(0)\n",
    "text_dict={0:'Mask ON' ,1: 'NO Mask'}\n",
    "rect_color_dict={0:(0,255,0),1:(0,0,255)}\n",
    "\n",
    "SUBJECT = \"Subject\"\n",
    "TEXT = \"One person violated Face Mask Policy. A person has been detected without face mask\"\n",
    "while(True):\n",
    "    classifier = cv2.CascadeClassifier(haar_xml)\n",
    "    ret, img = vid_source.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = classifier.detectMultiScale(gray)\n",
    "\n",
    "    for(x,y,w,h) in faces:\n",
    "        face_img = gray[y:y+h,x:x+w]\n",
    "        resized_img = cv2.resize(face_img,(112,112))\n",
    "        normalized_img = resized_img/255.0\n",
    "        reshaped_img = np.reshape(normalized_img,(1,112,112,1))\n",
    "        result=model.predict(reshaped_img)\n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),rect_color_dict[label],2)\n",
    "        cv2.rectangle(img,(x,y-40),(x+w,y),rect_color_dict[label],-1)\n",
    "        cv2.putText(img,text_dict[label], (x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,0,0),2)\n",
    "        cv2.imshow(\"img\", img)\n",
    "        cv2.waitKey(1)\n",
    "        if (label == 1):\n",
    "            messagebox.showwarning(\"WARNING\",\"Access Denied. Please wear a Face Mask\")\n",
    "            message = 'Subject: {}\\n\\n{}'.format(SUBJECT, TEXT)\n",
    "            mail = smtplib.SMTP('smtp.gmail.com',587)\n",
    "            mail.ehlo()\n",
    "            mail.starttls()\n",
    "            mail.login('facemaskad01@gmail.com','aDMin@10')\n",
    "            mail.sendmail('facemaskad01@gmail.com','facemaskad01@gmail.com',message)\n",
    "            mail.close\n",
    "        else:\n",
    "            pass\n",
    "            break\n",
    "#vid_source = cv2.VideoCapture(0)\n",
    "#vid_source.open(0, cv2.CAP_DSHOW)\n",
    "#while(True):\n",
    " #   ret, img = vid_source.read()\n",
    "  #  cv2.imshow(\"Face mask detection\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    vid_source.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
